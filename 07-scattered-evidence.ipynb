{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "intro_md",
   "metadata": {},
   "source": [
    "# RAG Failure #7: The \"Scattered Evidence\" Fragment (Low Recall)\n",
    "\n",
    "## The Problem\n",
    "Standard RAG relies on a `top_k` parameter (usually 3 to 5) to fit context into the LLM. \n",
    "If the user asks for a comprehensive list (e.g., \"List **all** safety features of the Model-X\"), and these features are mentioned one-by-one across **10 different pages** of a manual, the Vector Retriever will only fetch the top 3 pages. The LLM will confidentally list 3 features and miss the other 7.\n",
    "\n",
    "## The Scenario: Product Safety Compliance\n",
    "**Query:** \"List all safety certifications and features of the **Model-X** Industrial Robot.\"\n",
    "\n",
    "**The Scattered Data:**\n",
    "-   **Doc 1 (Intro):** \"The Model-X features a reinforced **Titanium Chassis**.\"\n",
    "-   **Doc 2 (Electrical):** \"Circuitry in the Model-X includes **Surge Protection**.\"\n",
    "-   **Doc 3 (Vision):** \"Model-X uses **Lidar Object Avoidance**.\"\n",
    "-   **Doc 4 (Emergency):** \"Standard **Red-Stop Button** is located on the Model-X rear.\"\n",
    "-   **Doc 5 (Compliance):** \"Model-X is **ISO-9001 Certified**.\"\n",
    "-   **Doc 6 (Distractor):** \"The Model-Y features **Voice Control**.\"\n",
    "\n",
    "**Naive RAG Failure:** With `k=2` or `k=3`, it retrieves Doc 1, 3, and 5. It misses Electrical (Doc 2) and Emergency (Doc 4). The answer is incomplete.\n",
    "\n",
    "**KG Solution:** We treat 'Model-X' as a central node. During ingestion, we attach every feature found in *any* document to this node. The query simply returns all neighbors of 'Model-X'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "setup_libs",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Step 1: Environment Setup ---\n",
    "!pip install -q langchain langchain-community langchain-huggingface faiss-cpu networkx transformers sentence-transformers accelerate bitsandbytes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "model_load",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading TinyLlama-1.1B-Chat-v1.0...\n",
      "Model loaded. Pipeline ready.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import pipeline, AutoTokenizer, AutoModelForCausalLM\n",
    "from langchain_huggingface import HuggingFacePipeline, HuggingFaceEmbeddings\n",
    "import networkx as nx\n",
    "\n",
    "# --- Step 2: Load Model ---\n",
    "model_id = \"TinyLlama/TinyLlama-1.1B-Chat-v1.0\"\n",
    "\n",
    "print(f\"Loading {model_id}...\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_id)\n",
    "\n",
    "pipe = pipeline(\n",
    "    \"text-generation\", \n",
    "    model=model, \n",
    "    tokenizer=tokenizer, \n",
    "    max_new_tokens=256, \n",
    "    temperature=0.1, \n",
    "    do_sample=True\n",
    ")\n",
    "\n",
    "llm = HuggingFacePipeline(pipeline=pipe)\n",
    "embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "print(\"Model loaded. Pipeline ready.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "data_sim",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created 6 Scattered Documents.\n",
      "Doc 1: [Manual Sec 1] The Model-X features a reinforced Titanium Chassis for impact resistance.\n",
      "Doc 2: [Manual Sec 2] Electrical circuitry in the Model-X includes active Surge Protection.\n",
      "Doc 3: [Manual Sec 3] For navigation, the Model-X uses Lidar Object Avoidance technology.\n",
      "Doc 4: [Manual Sec 4] A physical Red-Stop Button is located on the Model-X rear panel.\n",
      "Doc 5: [Compliance Cert] The Model-X is fully ISO-9001 Certified for factory use.\n",
      "Doc 6: [Ad Brochure] The new Model-Y features Voice Control and AI Chat.\n"
     ]
    }
   ],
   "source": [
    "from langchain.docstore.document import Document\n",
    "\n",
    "# --- Step 3: Simulate Scattered Attributes ---\n",
    "# 5 Docs describing Model-X. 1 Doc describing Model-Y.\n",
    "# A Retriever with k=2 or k=3 is GUARANTEED to miss facts.\n",
    "raw_texts = [\n",
    "    \"[Manual Sec 1] The Model-X features a reinforced Titanium Chassis for impact resistance.\",\n",
    "    \"[Manual Sec 2] Electrical circuitry in the Model-X includes active Surge Protection.\",\n",
    "    \"[Manual Sec 3] For navigation, the Model-X uses Lidar Object Avoidance technology.\",\n",
    "    \"[Manual Sec 4] A physical Red-Stop Button is located on the Model-X rear panel.\",\n",
    "    \"[Compliance Cert] The Model-X is fully ISO-9001 Certified for factory use.\",\n",
    "    # Distractor\n",
    "    \"[Ad Brochure] The new Model-Y features Voice Control and AI Chat.\"\n",
    "]\n",
    "\n",
    "docs = [Document(page_content=t) for t in raw_texts]\n",
    "print(f\"Created {len(docs)} Scattered Documents.\")\n",
    "for i, d in enumerate(docs):\n",
    "    print(f\"Doc {i+1}: {d.page_content}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "naive_rag_run",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- NAIVE RAG (Low Recall) ---\n",
      "Query: List all safety features and certifications of the Model-X.\n",
      "\n",
      "Retrieved Context (k=2):\n",
      "1. [Compliance Cert] The Model-X is fully ISO-9001 Certified for factory use.\n",
      "2. [Manual Sec 1] The Model-X features a reinforced Titanium Chassis for impact resistance.\n",
      "\n",
      "LLM Answer:\n",
      "Based on the context provided, the safety features and certifications of the Model-X are:\n",
      "1. ISO-9001 Certified\n",
      "2. Reinforced Titanium Chassis\n",
      "\n",
      "ANALYSIS:\n",
      "The LLM missed 3 CRITICAL features (Surge Protection, Lidar, Red-Stop Button). \n",
      "Why? Because k=2 limited the input. The LLM cannot list what it cannot see.\n"
     ]
    }
   ],
   "source": [
    "# --- Step 4: Naive RAG Implementation ---\n",
    "from langchain_community.vectorstores import FAISS\n",
    "\n",
    "print(\"\\n--- NAIVE RAG (Low Recall) ---\")\n",
    "query = \"List all safety features and certifications of the Model-X.\"\n",
    "print(f\"Query: {query}\")\n",
    "\n",
    "# 1. Indexing\n",
    "vectorstore = FAISS.from_documents(docs, embeddings)\n",
    "\n",
    "# 2. Retrieval\n",
    "# We set k=2 to demonstrate the fragmentation problem vividly.\n",
    "# Even with k=4, we would miss 1 document.\n",
    "retriever = vectorstore.as_retriever(search_kwargs={\"k\": 2})\n",
    "retrieved_docs = retriever.invoke(query)\n",
    "\n",
    "print(\"\\nRetrieved Context (k=2):\")\n",
    "context_str = \"\"\n",
    "for i, d in enumerate(retrieved_docs):\n",
    "    print(f\"{i+1}. {d.page_content}\")\n",
    "    context_str += d.page_content + \"\\n\"\n",
    "\n",
    "# 3. Generation\n",
    "prompt = f\"<|system|>\\nList every feature mentioned.\\n<|user|>\\nContext:\\n{context_str}\\nQuestion:\\n{query}\\n<|assistant|>\"\n",
    "response = llm.invoke(prompt)\n",
    "cleaned_response = response.split(\"<|assistant|>\")[-1].strip()\n",
    "\n",
    "print(\"\\nLLM Answer:\")\n",
    "print(cleaned_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "kg_extraction_cluster",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- ATTRIBUTE ACCUMULATION (KG Build) ---\n",
      "\n",
      "Parsing: [Manual Sec 1] The Model-X features a reinforced Titanium Chassis for impact resistance.\n",
      "   [Extracted]: Model-X | HAS_FEATURE | Titanium Chassis\n",
      "   [Action]: Attached 'Titanium Chassis' to 'Model-X'\n",
      "\n",
      "Parsing: [Manual Sec 2] Electrical circuitry in the Model-X includes active Surge Protection.\n",
      "   [Extracted]: Model-X | HAS_FEATURE | Surge Protection\n",
      "   [Action]: Attached 'Surge Protection' to 'Model-X'\n",
      "\n",
      "Parsing: [Manual Sec 3] For navigation, the Model-X uses Lidar Object Avoidance technology.\n",
      "   [Extracted]: Model-X | HAS_FEATURE | Lidar Object Avoidance\n",
      "   [Action]: Attached 'Lidar Object Avoidance' to 'Model-X'\n",
      "...\n"
     ]
    }
   ],
   "source": [
    "# --- Step 5: Attribute Accumulation Pipeline ---\n",
    "# We process ALL documents. The graph acts as the \"Global Memory\".\n",
    "# We normalize the Subject ('Model-X') so all features attach to one node.\n",
    "\n",
    "kg = nx.DiGraph()\n",
    "\n",
    "def extract_features(text):\n",
    "    \"\"\"\n",
    "    Extracts Product -> Feature relationships.\n",
    "    \"\"\"\n",
    "    prompt = f\"\"\"<|system|>\n",
    "    Extract the Product and the specific Feature/Cert mentioned.\n",
    "    Format: Product | HAS_FEATURE | Feature\n",
    "    <|user|>\n",
    "    Text: {text}\n",
    "    <|assistant|>\"\"\"\n",
    "    \n",
    "    raw = llm.invoke(prompt)\n",
    "    out = raw.split(\"<|assistant|>\")[-1].strip()\n",
    "    if \"|\" in out:\n",
    "        return [p.strip() for p in out.split(\"|\")]\n",
    "    return []\n",
    "\n",
    "print(\"\\n--- ATTRIBUTE ACCUMULATION (KG Build) ---\")\n",
    "\n",
    "for doc in docs:\n",
    "    print(f\"\\nParsing: {doc.page_content}\")\n",
    "    parts = extract_features(doc.page_content)\n",
    "    \n",
    "    if len(parts) >= 3:\n",
    "        prod, rel, feature = parts[0], parts[1], parts[2]\n",
    "        \n",
    "        # Normalize the product name to ensure connectivity\n",
    "        if \"Model-X\" in prod: prod_id = \"Model-X\"\n",
    "        elif \"Model-Y\" in prod: prod_id = \"Model-Y\"\n",
    "        else: prod_id = prod\n",
    "        \n",
    "        print(f\"   [Extracted]: {prod_id} | HAS_FEATURE | {feature}\")\n",
    "        kg.add_edge(prod_id, feature, relation=\"HAS_FEATURE\")\n",
    "        print(f\"   [Action]: Attached '{feature}' to '{prod_id}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "kg_solution_cluster",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- 1-HOP NEIGHBORHOOD SEARCH ---\n",
      "Query: \"List all safety features and certifications of the Model-X.\"\n",
      "Target Entity: 'Model-X'\n",
      "\n",
      "Graph Retrieval (All Neighbors):\n",
      "  - Titanium Chassis\n",
      "  - Surge Protection\n",
      "  - Lidar Object Avoidance\n",
      "  - Red-Stop Button\n",
      "  - ISO-9001 Certified\n",
      "\n",
      "Total Features Retrieved: 5\n",
      "\n",
      "Final Answer (100% Recall):\n",
      "The Model-X comes equipped with 5 key features: Titanium Chassis, Surge Protection, Lidar Object Avoidance, Red-Stop Button, ISO-9001 Certified.\n"
     ]
    }
   ],
   "source": [
    "# --- Step 6: The Solution (Neighborhood Search) ---\n",
    "# We retrieve the central node and ALL its connected neighbors.\n",
    "# This simulates 'Infinite K' for this specific topic.\n",
    "\n",
    "print(\"\\n--- 1-HOP NEIGHBORHOOD SEARCH ---\")\n",
    "print(f\"Query: \\\"{query}\\\"\")\n",
    "\n",
    "target = \"Model-X\"\n",
    "print(f\"Target Entity: '{target}'\")\n",
    "\n",
    "if target in kg:\n",
    "    # Get all features (successors)\n",
    "    features = list(kg.successors(target))\n",
    "    \n",
    "    print(f\"\\nGraph Retrieval (All Neighbors):\")\n",
    "    for f in features:\n",
    "        print(f\"  - {f}\")\n",
    "        \n",
    "    print(f\"\\nTotal Features Retrieved: {len(features)}\")\n",
    "    \n",
    "    # Formulate Answer\n",
    "    print(f\"\\nFinal Answer (100% Recall):\\nThe {target} comes equipped with {len(features)} key features: {', '.join(features)}.\")\n",
    "else:\n",
    "    print(\"Entity not found in graph.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
