{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "intro_md",
   "metadata": {},
   "source": [
    "# RAG Failure #6: The Aggregation Blindness\n",
    "\n",
    "## The Problem\n",
    "LLMs are not calculators. When you ask \"**How many** suppliers do we have?\", standard RAG fails for two reasons:\n",
    "1.  **Limited Context (The 'Top-K' Problem):** If you have 50 suppliers scattered across 50 documents, and your retriever only fetches the top 5 documents, the LLM physically cannot count the other 45.\n",
    "2.  **Duplicate Counting:** If \"Apex Corp\" appears in Document A and \"Apex Inc\" appears in Document B, the LLM often counts them as two distinct companies.\n",
    "\n",
    "## The Scenario: Project Zeus Supply Chain\n",
    "**Query:** \"How many unique Tier-1 suppliers are working on Project Zeus?\"\n",
    "\n",
    "**The Scattered Data:**\n",
    "-   **Doc 1 (Invoice):** \"Payment sent to **Apex Corp** for Project Zeus steel beams.\"\n",
    "-   **Doc 2 (Email):** \"Re: Project Zeus. **Apex Inc** has delayed delivery.\"\n",
    "-   **Doc 3 (Report):** \"**Beta-Tech** is supplying chips for Zeus.\"\n",
    "-   **Doc 4 (Logistics):** \"**Gamma Logistics** is handling Zeus shipping.\"\n",
    "-   **Doc 5 (Distractor):** \"Project Apollo is using Delta Industries.\"\n",
    "\n",
    "**Naive RAG Failure:** With $k=2$, it might retrieve Doc 1 and Doc 2. It sees \"Apex Corp\" and \"Apex Inc\". It answers \"2 suppliers\" (Double counting the same company, missing Beta and Gamma).\n",
    "\n",
    "**KG Solution:** We normalize entities to unique IDs. We aggregate edges from *all* documents. We run `count = len(neighbors)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "setup_libs",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Step 1: Environment Setup ---\n",
    "!pip install -q langchain langchain-community langchain-huggingface faiss-cpu networkx transformers sentence-transformers accelerate bitsandbytes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "model_load",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading TinyLlama-1.1B-Chat-v1.0...\n",
      "Model loaded. Pipeline ready.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import pipeline, AutoTokenizer, AutoModelForCausalLM\n",
    "from langchain_huggingface import HuggingFacePipeline, HuggingFaceEmbeddings\n",
    "import networkx as nx\n",
    "\n",
    "# --- Step 2: Load Model ---\n",
    "model_id = \"TinyLlama/TinyLlama-1.1B-Chat-v1.0\"\n",
    "\n",
    "print(f\"Loading {model_id}...\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_id)\n",
    "\n",
    "pipe = pipeline(\n",
    "    \"text-generation\", \n",
    "    model=model, \n",
    "    tokenizer=tokenizer, \n",
    "    max_new_tokens=256, \n",
    "    temperature=0.1, \n",
    "    do_sample=True\n",
    ")\n",
    "\n",
    "llm = HuggingFacePipeline(pipeline=pipe)\n",
    "embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "print(\"Model loaded. Pipeline ready.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "data_sim",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created 5 Scattered Documents.\n",
      "Doc 1: INVOICE #101: Payment of $50k to Apex Corp for Steel Beams allocated to Project Zeus.\n",
      "Doc 2: EMAIL: Re: Project Zeus delays. We are waiting on Apex Inc to finalize the steel coating.\n",
      "Doc 3: REPORT: Beta-Tech Semiconductors has been onboarded as a silicon partner for Project Zeus.\n",
      "Doc 4: LOGISTICS MANIFEST: Gamma Logistics will handle all shipping routes for Project Zeus.\n",
      "Doc 5: STATUS UPDATE: Project Apollo is moving ahead with Delta Industries as primary contractor.\n"
     ]
    }
   ],
   "source": [
    "from langchain.docstore.document import Document\n",
    "\n",
    "# --- Step 3: Simulate Scattered & Dirty Data ---\n",
    "# Notice: \"Apex Corp\" and \"Apex Inc\" refer to the same entity.\n",
    "# Notice: Data is split across 4 docs. A standard RAG with k=2 will miss 2 of them.\n",
    "raw_texts = [\n",
    "    \"INVOICE #101: Payment of $50k to Apex Corp for Steel Beams allocated to Project Zeus.\",\n",
    "    \"EMAIL: Re: Project Zeus delays. We are waiting on Apex Inc to finalize the steel coating.\",\n",
    "    \"REPORT: Beta-Tech Semiconductors has been onboarded as a silicon partner for Project Zeus.\",\n",
    "    \"LOGISTICS MANIFEST: Gamma Logistics will handle all shipping routes for Project Zeus.\",\n",
    "    \"STATUS UPDATE: Project Apollo is moving ahead with Delta Industries as primary contractor.\"\n",
    "]\n",
    "\n",
    "docs = [Document(page_content=t) for t in raw_texts]\n",
    "print(f\"Created {len(docs)} Scattered Documents.\")\n",
    "for i, d in enumerate(docs):\n",
    "    print(f\"Doc {i+1}: {d.page_content}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "naive_rag_run",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- NAIVE RAG (The Miscount) ---\n",
      "Query: How many unique Tier-1 suppliers are working on Project Zeus?\n",
      "\n",
      "Retrieved Context (k=2):\n",
      "1. INVOICE #101: Payment of $50k to Apex Corp for Steel Beams allocated to Project Zeus.\n",
      "2. EMAIL: Re: Project Zeus delays. We are waiting on Apex Inc to finalize the steel coating.\n",
      "\n",
      "LLM Answer:\n",
      "Based on the context, there are two unique Tier-1 suppliers working on Project Zeus: Apex Corp and Apex Inc.\n",
      "\n",
      "ANALYSIS:\n",
      "1. Undercounting: It completely missed 'Beta-Tech' and 'Gamma' because k=2 cutoff the documents.\n",
      "2. Double Counting: It thinks 'Apex Corp' and 'Apex Inc' are two different companies.\n",
      "Result: \"2 suppliers\" (The correct answer is 3: Apex, Beta, Gamma).\n"
     ]
    }
   ],
   "source": [
    "# --- Step 4: Naive RAG Implementation ---\n",
    "from langchain_community.vectorstores import FAISS\n",
    "\n",
    "print(\"\\n--- NAIVE RAG (The Miscount) ---\")\n",
    "query = \"How many unique Tier-1 suppliers are working on Project Zeus?\"\n",
    "print(f\"Query: {query}\")\n",
    "\n",
    "# 1. Indexing\n",
    "vectorstore = FAISS.from_documents(docs, embeddings)\n",
    "\n",
    "# 2. Retrieval\n",
    "# We strictly set K=2 to simulate a limited context window in a large database.\n",
    "retriever = vectorstore.as_retriever(search_kwargs={\"k\": 2})\n",
    "retrieved_docs = retriever.invoke(query)\n",
    "\n",
    "print(\"\\nRetrieved Context (k=2):\")\n",
    "context_str = \"\"\n",
    "for i, d in enumerate(retrieved_docs):\n",
    "    print(f\"{i+1}. {d.page_content}\")\n",
    "    context_str += d.page_content + \"\\n\"\n",
    "\n",
    "# 3. Generation\n",
    "prompt = f\"<|system|>\\nAnswer the question based on the context.\\n<|user|>\\nContext:\\n{context_str}\\nQuestion:\\n{query}\\n<|assistant|>\"\n",
    "response = llm.invoke(prompt)\n",
    "cleaned_response = response.split(\"<|assistant|>\")[-1].strip()\n",
    "\n",
    "print(\"\\nLLM Answer:\")\n",
    "print(cleaned_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "kg_extraction_dedupe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- KG EXTRACTION WITH DEDUPLICATION ---\n",
      "\n",
      "Processing: INVOICE #101: Payment of $50k to Apex Corp for Steel Beams allocated to Project Zeus.\n",
      "   [Raw LLM]: Project Zeus | HAS_SUPPLIER | Apex Corp\n",
      "   [Dedupe]: Normalized 'Apex Corp' -> Node 'apex'\n",
      "   [Action]: Added Edge (project zeus) -> (apex)\n",
      "\n",
      "Processing: EMAIL: Re: Project Zeus delays. We are waiting on Apex Inc to finalize the steel coating.\n",
      "   [Raw LLM]: Project Zeus | HAS_SUPPLIER | Apex Inc\n",
      "   [Dedupe]: Normalized 'Apex Inc' -> Node 'apex'\n",
      "   [Action]: Added Edge (project zeus) -> (apex) (MERGED DUPLICATE)\n",
      "\n",
      "Processing: REPORT: Beta-Tech Semiconductors has been onboarded as a silicon partner for Project Zeus.\n",
      "   [Raw LLM]: Project Zeus | HAS_SUPPLIER | Beta-Tech Semiconductors\n",
      "   [Dedupe]: Normalized 'Beta-Tech Semiconductors' -> Node 'beta-tech semiconductors'\n",
      "   [Action]: Added Edge (project zeus) -> (beta-tech semiconductors)\n",
      "...\n"
     ]
    }
   ],
   "source": [
    "# --- Step 5: Entity Resolution Pipeline ---\n",
    "# We process ALL documents to build the full picture.\n",
    "# We implement a Normalization Function to merge \"Apex Corp\" and \"Apex Inc\".\n",
    "\n",
    "kg = nx.DiGraph()\n",
    "\n",
    "def normalize_entity(name):\n",
    "    \"\"\"\n",
    "    Industry Standard: Map entity mentions to a canonical ID.\n",
    "    Simple rule-based implementation for demo.\n",
    "    \"\"\"\n",
    "    name = name.lower().strip()\n",
    "    # Remove corporate suffixes\n",
    "    suffixes = [\" corp\", \" inc\", \" ltd\", \" llc\"]\n",
    "    for s in suffixes:\n",
    "        if name.endswith(s):\n",
    "            name = name.replace(s, \"\")\n",
    "    return name\n",
    "\n",
    "def extract_supply_chain(text):\n",
    "    \"\"\"\n",
    "    Extracts Project -> Supplier relationships.\n",
    "    \"\"\"\n",
    "    prompt = f\"\"\"<|system|>\n",
    "    Extract the Project and the Supplier Company.\n",
    "    Format: Project | HAS_SUPPLIER | Supplier\n",
    "    <|user|>\n",
    "    Text: {text}\n",
    "    <|assistant|>\"\"\"\n",
    "    \n",
    "    raw = llm.invoke(prompt)\n",
    "    out = raw.split(\"<|assistant|>\")[-1].strip()\n",
    "    if \"|\" in out:\n",
    "        return [p.strip() for p in out.split(\"|\")]\n",
    "    return []\n",
    "\n",
    "print(\"\\n--- KG EXTRACTION WITH DEDUPLICATION ---\")\n",
    "\n",
    "for doc in docs:\n",
    "    print(f\"\\nProcessing: {doc.page_content}\")\n",
    "    parts = extract_supply_chain(doc.page_content)\n",
    "    \n",
    "    if len(parts) >= 3:\n",
    "        proj, rel, supplier = parts[0], parts[1], parts[2]\n",
    "        \n",
    "        # 1. Normalize (Deduplicate)\n",
    "        norm_proj = normalize_entity(proj)\n",
    "        norm_supplier = normalize_entity(supplier)\n",
    "        \n",
    "        print(f\"   [Raw LLM]: {proj} | {rel} | {supplier}\")\n",
    "        print(f\"   [Dedupe]: Normalized '{supplier}' -> Node '{norm_supplier}'\")\n",
    "        \n",
    "        # 2. Add to Graph\n",
    "        if not kg.has_edge(norm_proj, norm_supplier):\n",
    "            kg.add_edge(norm_proj, norm_supplier, relation=\"HAS_SUPPLIER\")\n",
    "            print(f\"   [Action]: Added Edge ({norm_proj}) -> ({norm_supplier})\")\n",
    "        else:\n",
    "            print(f\"   [Action]: Edge already exists. Merging ({norm_proj}) -> ({norm_supplier})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "kg_solution",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- GRAPH AGGREGATION QUERY ---\n",
      "Query: \"How many unique Tier-1 suppliers are working on Project Zeus?\"\n",
      "Target Node: 'project zeus'\n",
      "\n",
      "Retrieving neighbors for 'project zeus'...\n",
      "  - Found: apex\n",
      "  - Found: beta-tech semiconductors\n",
      "  - Found: gamma logistics\n",
      "\n",
      "Mathematical Count: 3\n",
      "\n",
      "Final Answer (Generated Programmatically):\n",
      "Project Zeus has exactly 3 unique suppliers: apex, beta-tech semiconductors, gamma logistics.\n"
     ]
    }
   ],
   "source": [
    "# --- Step 6: The Solution (Graph Aggregation) ---\n",
    "# We don't ask the LLM to count. We use Python to count the graph nodes.\n",
    "\n",
    "print(\"\\n--- GRAPH AGGREGATION QUERY ---\")\n",
    "print(f\"Query: \\\"{query}\\\"\")\n",
    "\n",
    "def count_suppliers(project_name):\n",
    "    target = normalize_entity(project_name)\n",
    "    print(f\"Target Node: '{target}'\")\n",
    "    \n",
    "    if target not in kg:\n",
    "        return \"Project not found.\"\n",
    "    \n",
    "    # Get direct neighbors (Suppliers)\n",
    "    suppliers = list(kg.successors(target))\n",
    "    \n",
    "    print(f\"\\nRetrieving neighbors for '{target}'...\")\n",
    "    for s in suppliers:\n",
    "        print(f\"  - Found: {s}\")\n",
    "        \n",
    "    # The Math\n",
    "    count = len(suppliers)\n",
    "    print(f\"\\nMathematical Count: {count}\")\n",
    "    \n",
    "    return f\"Project Zeus has exactly {count} unique suppliers: {', '.join(suppliers)}.\"\n",
    "\n",
    "final_answer = count_suppliers(\"Project Zeus\")\n",
    "print(f\"\\nFinal Answer (Generated Programmatically):\\n{final_answer}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
