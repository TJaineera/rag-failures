{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "intro_md",
   "metadata": {},
   "source": [
    "# RAG Failure #11: The Negation & Absence Failure\n",
    "\n",
    "## The Problem\n",
    "Vector Search is fundamentally **additive**. It finds things that *are* present. It struggles to find things that are *absent*.\n",
    "If a user asks, **\"Which products do NOT contain peanuts?\"**, the vector embedding for \"Peanuts\" dominates the search. The retriever fetches documents *full* of the word \"Peanuts\". The LLM then sees a context full of peanut products and often fails to identify the safe options (which likely didn't mention peanuts at all, leading to low retrieval score).\n",
    "\n",
    "## The Scenario: Allergen Screening\n",
    "**Query:** \"Which granola bars are safe for a user with a Peanut Allergy?\"\n",
    "\n",
    "**The Hazardous Data:**\n",
    "1.  **Doc 1 (Nutty-Crunch):** \"The **Nutty-Crunch** bar is packed with protein. Ingredients: Oats, **Peanuts**, Honey.\"\n",
    "2.  **Doc 2 (Cocoa-Delight):** \"**Cocoa-Delight** is a sweet treat. Ingredients: Rolled Oats, Cocoa Butter, Almonds, Sugar.\"\n",
    "3.  **Doc 3 (Berry-Blast):** \"**Berry-Blast** is made with real fruit. Ingredients: Dried Cranberries, Wheat, Soy Lecithin.\"\n",
    "4.  **Doc 4 (Warning):** \"**Berry-Blast** is manufactured in a facility that processes **Peanuts**.\"\n",
    "\n",
    "**Naive RAG Failure:** \n",
    "1.  It retrieves Doc 1 and Doc 4 because they contain the word \"Peanuts\".\n",
    "2.  It **misses** Doc 2 (Cocoa-Delight) because it never mentions \"Peanuts\" (Low similarity).\n",
    "3.  Result: The user asks for safe bars, but the system only talks about the unsafe ones.\n",
    "\n",
    "**KG Solution:** \n",
    "We use **Set Difference**. \n",
    "`Safe_Products = All_Products - (Products_With_Peanuts + Products_With_Traces)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "setup_libs",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Step 1: Environment Setup ---\n",
    "!pip install -q langchain langchain-community langchain-huggingface faiss-cpu networkx transformers sentence-transformers accelerate bitsandbytes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "model_load",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading TinyLlama-1.1B-Chat-v1.0...\n",
      "Model loaded. Pipeline ready.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import pipeline, AutoTokenizer, AutoModelForCausalLM\n",
    "from langchain_huggingface import HuggingFacePipeline, HuggingFaceEmbeddings\n",
    "import networkx as nx\n",
    "\n",
    "# --- Step 2: Load Model ---\n",
    "model_id = \"TinyLlama/TinyLlama-1.1B-Chat-v1.0\"\n",
    "\n",
    "print(f\"Loading {model_id}...\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_id)\n",
    "\n",
    "pipe = pipeline(\n",
    "    \"text-generation\", \n",
    "    model=model, \n",
    "    tokenizer=tokenizer, \n",
    "    max_new_tokens=256, \n",
    "    temperature=0.1, \n",
    "    do_sample=True\n",
    ")\n",
    "\n",
    "llm = HuggingFacePipeline(pipeline=pipe)\n",
    "embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "print(\"Model loaded. Pipeline ready.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "data_sim",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created 4 Label Documents.\n",
      "Doc 1: [Product Label] Name: Nutty-Crunch. Description: High protein energy bar. Ingredients List: Oats, Peanuts, Honey, Whey Protein.\n",
      "Doc 2: [Product Label] Name: Cocoa-Delight. Description: A chocolate lover's dream. Ingredients List: Rolled Oats, Cocoa Butter, Almonds, Cane Sugar.\n",
      "Doc 3: [Product Label] Name: Berry-Blast. Description: Real fruit antioxidant bar. Ingredients List: Dried Cranberries, Wheat Flour, Soy Lecithin.\n",
      "Doc 4: [Factory Audit] Warning: The Berry-Blast production line is located in a facility that processes Peanuts and Tree Nuts.\n"
     ]
    }
   ],
   "source": [
    "from langchain.docstore.document import Document\n",
    "\n",
    "# --- Step 3: Simulate Product Labels ---\n",
    "raw_texts = [\n",
    "    \"[Product Label] Name: Nutty-Crunch. Description: High protein energy bar. Ingredients List: Oats, Peanuts, Honey, Whey Protein.\",\n",
    "    \"[Product Label] Name: Cocoa-Delight. Description: A chocolate lover's dream. Ingredients List: Rolled Oats, Cocoa Butter, Almonds, Cane Sugar.\",\n",
    "    \"[Product Label] Name: Berry-Blast. Description: Real fruit antioxidant bar. Ingredients List: Dried Cranberries, Wheat Flour, Soy Lecithin.\",\n",
    "    \"[Factory Audit] Warning: The Berry-Blast production line is located in a facility that processes Peanuts and Tree Nuts.\"\n",
    "]\n",
    "\n",
    "docs = [Document(page_content=t) for t in raw_texts]\n",
    "print(f\"Created {len(docs)} Label Documents.\")\n",
    "for i, d in enumerate(docs):\n",
    "    print(f\"Doc {i+1}: {d.page_content}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "naive_rag_run",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- NAIVE RAG (Negation Blindness) ---\n",
      "Query: Which granola bars are safe for someone with a Peanut Allergy?\n",
      "\n",
      "Retrieved Context (k=2):\n",
      "1. [Factory Audit] Warning: The Berry-Blast production line is located in a facility that processes Peanuts and Tree Nuts.\n",
      "2. [Product Label] Name: Nutty-Crunch. Description: High protein energy bar. Ingredients List: Oats, Peanuts, Honey, Whey Protein.\n",
      "\n",
      "LLM Answer:\n",
      "Based on the context, the Berry-Blast production line processes Peanuts, and the Nutty-Crunch bar contains Peanuts. Therefore, neither of these bars is safe for someone with a Peanut Allergy.\n",
      "\n",
      "ANALYSIS:\n",
      "Failure Mode: 'Omission'.\n",
      "The retriever fetched the DANGEROUS items because they matched the word 'Peanut'. \n",
      "It completely missed 'Cocoa-Delight' because that document does not contain the word 'Peanut'.\n",
      "The LLM correctly identified the retrieved items as unsafe, but failed to provide the user with the SAFE alternative.\n"
     ]
    }
   ],
   "source": [
    "# --- Step 4: Naive RAG Implementation ---\n",
    "from langchain_community.vectorstores import FAISS\n",
    "\n",
    "print(\"\\n--- NAIVE RAG (Negation Blindness) ---\")\n",
    "query = \"Which granola bars are safe for someone with a Peanut Allergy?\"\n",
    "print(f\"Query: {query}\")\n",
    "\n",
    "# 1. Indexing\n",
    "vectorstore = FAISS.from_documents(docs, embeddings)\n",
    "\n",
    "# 2. Retrieval\n",
    "# The user types \"Peanut Allergy\". The vector database hunts for \"Peanut\".\n",
    "# It finds Nutty-Crunch (Doc 1) and Factory Audit (Doc 4).\n",
    "# It IGNORES Cocoa-Delight (Doc 2) because distance(\"Peanut\", \"Almond\") is far.\n",
    "retriever = vectorstore.as_retriever(search_kwargs={\"k\": 2})\n",
    "retrieved_docs = retriever.invoke(query)\n",
    "\n",
    "print(\"\\nRetrieved Context (k=2):\")\n",
    "context_str = \"\"\n",
    "for i, d in enumerate(retrieved_docs):\n",
    "    print(f\"{i+1}. {d.page_content}\")\n",
    "    context_str += d.page_content + \"\\n\"\n",
    "\n",
    "# 3. Generation\n",
    "prompt = f\"<|system|>\\nAnswer the question based on the context. List safe options.\\n<|user|>\\nContext:\\n{context_str}\\nQuestion:\\n{query}\\n<|assistant|>\"\n",
    "response = llm.invoke(prompt)\n",
    "cleaned_response = response.split(\"<|assistant|>\")[-1].strip()\n",
    "\n",
    "print(\"\\nLLM Answer:\")\n",
    "print(cleaned_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "kg_extraction_allergen",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- INGREDIENT PARSING PIPELINE ---\n",
      "\n",
      "Processing: [Product Label] Name: Nutty-Crunch. Description: High protein energy bar. Ingredients List: Oats, Peanuts, Honey, Whey Protein.\n",
      "   [Extracted]: Nutty-Crunch | CONTAINS | Oats\n",
      "   [Extracted]: Nutty-Crunch | CONTAINS | Peanuts\n",
      "   [Extracted]: Nutty-Crunch | CONTAINS | Honey\n",
      "\n",
      "Processing: [Product Label] Name: Cocoa-Delight. Description: A chocolate lover's dream. Ingredients List: Rolled Oats, Cocoa Butter, Almonds, Cane Sugar.\n",
      "   [Extracted]: Cocoa-Delight | CONTAINS | Rolled Oats\n",
      "   [Extracted]: Cocoa-Delight | CONTAINS | Almonds\n",
      "\n",
      "Processing: [Factory Audit] Warning: The Berry-Blast production line is located in a facility that processes Peanuts and Tree Nuts.\n",
      "   [Extracted]: Berry-Blast | TRACES_OF | Peanuts\n",
      "   [Extracted]: Berry-Blast | TRACES_OF | Tree Nuts\n",
      "...\n"
     ]
    }
   ],
   "source": [
    "# --- Step 5: Ingredient Graph Construction ---\n",
    "# We extract specific edge types: CONTAINS vs TRACES_OF\n",
    "\n",
    "kg = nx.DiGraph()\n",
    "\n",
    "def extract_ingredients(text):\n",
    "    \"\"\"\n",
    "    Parses list format or warning sentences.\n",
    "    \"\"\"\n",
    "    prompt = f\"\"\"<|system|>\n",
    "    Extract the Product and the Ingredient.\n",
    "    If it's an ingredient list, use relation: CONTAINS\n",
    "    If it's a facility warning, use relation: TRACES_OF\n",
    "    Format: Product | RELATION | Ingredient\n",
    "    <|user|>\n",
    "    Text: {text}\n",
    "    <|assistant|>\"\"\"\n",
    "    \n",
    "    raw = llm.invoke(prompt)\n",
    "    out = raw.split(\"<|assistant|>\")[-1].strip()\n",
    "    if \"|\" in out:\n",
    "        # Handle multi-line extractions (LLMs sometimes output multiple lines)\n",
    "        lines = out.split(\"\\n\")\n",
    "        results = []\n",
    "        for line in lines:\n",
    "            if \"|\" in line:\n",
    "                results.append([p.strip() for p in line.split(\"|\")])\n",
    "        return results\n",
    "    return []\n",
    "\n",
    "print(\"\\n--- INGREDIENT PARSING PIPELINE ---\")\n",
    "\n",
    "for doc in docs:\n",
    "    print(f\"\\nProcessing: {doc.page_content}\")\n",
    "    triplets = extract_ingredients(doc.page_content)\n",
    "    \n",
    "    for parts in triplets:\n",
    "        if len(parts) >= 3:\n",
    "            prod, rel, ing = parts[0], parts[1], parts[2]\n",
    "            \n",
    "            # Normalize\n",
    "            prod = prod.replace(\"The \", \"\").replace(\" production line\", \"\")\n",
    "            ing = ing.replace(\" and \", \"\").replace(\".\", \"\")\n",
    "            \n",
    "            print(f\"   [Extracted]: {prod} | {rel} | {ing}\")\n",
    "            kg.add_edge(prod, ing, relation=rel)\n",
    "            \n",
    "            # Tag the product node so we can find 'All Products' later\n",
    "            kg.add_node(prod, type=\"Product\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "kg_solution_set_diff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- GRAPH SET DIFFERENCE (Safety Check) ---\n",
      "Query: \"Which granola bars are safe for someone with a Peanut Allergy?\"\n",
      "Target Allergen: 'Peanuts'\n",
      "\n",
      "1. Identifying ALL Products:\n",
      "   {'Nutty-Crunch', 'Cocoa-Delight', 'Berry-Blast'}\n",
      "\n",
      "2. Identifying UNSAFE Products (Connected to 'Peanuts'):\n",
      "   - Nutty-Crunch (Relation: CONTAINS)\n",
      "   - Berry-Blast (Relation: TRACES_OF)\n",
      "\n",
      "3. Calculating SAFE Products (All - Unsafe):\n",
      "   {'Cocoa-Delight'}\n",
      "\n",
      "Final Answer (Generated from Logic):\n",
      "The following products are safe (No Peanuts or Traces detected): Cocoa-Delight.\n"
     ]
    }
   ],
   "source": [
    "# --- Step 6: The Solution (Set Difference) ---\n",
    "\n",
    "print(\"\\n--- GRAPH SET DIFFERENCE (Safety Check) ---\")\n",
    "print(f\"Query: \\\"{query}\\\"\")\n",
    "\n",
    "allergen = \"Peanuts\"\n",
    "print(f\"Target Allergen: '{allergen}'\")\n",
    "\n",
    "def check_allergen_safety(allergen_name):\n",
    "    # 1. Get Set of All Products\n",
    "    all_products = {n for n, d in kg.nodes(data=True) if d.get('type') == 'Product'}\n",
    "    print(f\"\\n1. Identifying ALL Products:\\n   {all_products}\")\n",
    "    \n",
    "    # 2. Get Set of Unsafe Products (Predecessors of the Allergen)\n",
    "    # We look for nodes pointing TO the allergen\n",
    "    unsafe_products = set()\n",
    "    \n",
    "    # Handle simple matching for demo\n",
    "    target_nodes = [n for n in kg.nodes() if allergen_name in n]\n",
    "    \n",
    "    print(f\"\\n2. Identifying UNSAFE Products (Connected to '{allergen_name}'):\")\n",
    "    for target in target_nodes:\n",
    "        predecessors = list(kg.predecessors(target))\n",
    "        for p in predecessors:\n",
    "            rel = kg[p][target]['relation']\n",
    "            unsafe_products.add(p)\n",
    "            print(f\"   - {p} (Relation: {rel})\")\n",
    "            \n",
    "    # 3. Perform Set Difference\n",
    "    safe_products = all_products - unsafe_products\n",
    "    \n",
    "    print(f\"\\n3. Calculating SAFE Products (All - Unsafe):\\n   {safe_products}\")\n",
    "    \n",
    "    if safe_products:\n",
    "        return f\"The following products are safe (No {allergen_name} or Traces detected): {', '.join(safe_products)}.\"\n",
    "    else:\n",
    "        return \"No safe products found.\"\n",
    "\n",
    "final_answer = check_allergen_safety(allergen)\n",
    "\n",
    "print(f\"\\nFinal Answer (Generated from Logic):\\n{final_answer}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
